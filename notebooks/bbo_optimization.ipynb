{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Black-Box Optimisation (BBO) Capstone Project\n",
    "\n",
    "**Imperial College Business School - Machine Learning & AI Programme**\n",
    "\n",
    "This notebook implements Bayesian optimisation for eight unknown black-box functions, demonstrating the iterative process of querying, learning, and refining our search strategy.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup & Imports](#1.-Setup-&-Imports)\n",
    "2. [Understanding the Problem](#2.-Understanding-the-Problem)\n",
    "3. [Load Initial Data](#3.-Load-Initial-Data)\n",
    "4. [Gaussian Process Surrogate Model](#4.-Gaussian-Process-Surrogate-Model)\n",
    "5. [Acquisition Functions](#5.-Acquisition-Functions)\n",
    "6. [Optimisation Loop](#6.-Optimisation-Loop)\n",
    "7. [Results Analysis](#7.-Results-Analysis)\n",
    "8. [Generate Next Queries](#8.-Generate-Next-Queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, WhiteKernel\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Problem\n",
    "\n",
    "We have 8 black-box functions of varying dimensionality. Our goal is to **maximise** each function using limited queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function metadata\n",
    "FUNCTIONS = {\n",
    "    1: {\"dims\": 2, \"initial_points\": 10, \"analogy\": \"Radiation detection\"},\n",
    "    2: {\"dims\": 2, \"initial_points\": 10, \"analogy\": \"Drug efficacy\"},\n",
    "    3: {\"dims\": 3, \"initial_points\": 15, \"analogy\": \"Manufacturing quality\"},\n",
    "    4: {\"dims\": 4, \"initial_points\": 30, \"analogy\": \"Process optimisation\"},\n",
    "    5: {\"dims\": 4, \"initial_points\": 20, \"analogy\": \"Resource allocation\"},\n",
    "    6: {\"dims\": 5, \"initial_points\": 20, \"analogy\": \"Side effect minimisation\"},\n",
    "    7: {\"dims\": 6, \"initial_points\": 30, \"analogy\": \"Robot control\"},\n",
    "    8: {\"dims\": 8, \"initial_points\": 40, \"analogy\": \"Complex system tuning\"},\n",
    "}\n",
    "\n",
    "# Display function info\n",
    "func_df = pd.DataFrame([\n",
    "    {\"Function\": f\"F{k}\", **v} for k, v in FUNCTIONS.items()\n",
    "])\n",
    "print(\"Function Overview:\")\n",
    "display(func_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Initial Data\n",
    "\n",
    "Load the `.npy` files provided for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_function_data(func_num, data_dir=\"../data/raw\"):\n",
    "    \"\"\"Load data for a specific function.\"\"\"\n",
    "    import os\n",
    "    func_dir = os.path.join(data_dir, f\"function_{func_num}\")\n",
    "    X = np.load(os.path.join(func_dir, \"initial_inputs.npy\"))\n",
    "    Y = np.load(os.path.join(func_dir, \"initial_outputs.npy\"))\n",
    "    return X, Y.ravel()\n",
    "\n",
    "# Example: Load Function 1 data (if available)\n",
    "# X1, Y1 = load_function_data(1)\n",
    "# print(f\"Function 1: {X1.shape[0]} points, {X1.shape[1]} dimensions\")\n",
    "# print(f\"Output range: [{Y1.min():.4f}, {Y1.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulated Results (Rounds 1-5)\n",
    "\n",
    "Since we've completed 5 rounds, let's record all our observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results tracking from all rounds\n",
    "results = {\n",
    "    \"F1\": {\n",
    "        \"dims\": 2,\n",
    "        \"queries\": [\n",
    "            (\"0.000000-0.999999\", 0.0),           # R1\n",
    "            (\"0.999999-0.000000\", 0.0),           # R2\n",
    "            (\"0.500000-0.500000\", 2.68e-9),       # R3\n",
    "            (\"0.400000-0.600000\", 1.45e-23),      # R4\n",
    "            (\"0.600000-0.400000\", \"pending\"),     # R5\n",
    "        ],\n",
    "        \"best\": 2.68e-9,\n",
    "    },\n",
    "    \"F2\": {\n",
    "        \"dims\": 2,\n",
    "        \"queries\": [\n",
    "            (\"0.999999-0.050505\", -0.069),\n",
    "            (\"0.750000-0.950000\", 0.334),\n",
    "            (\"0.700000-0.930000\", 0.651),\n",
    "            (\"0.690000-0.940000\", 0.639),\n",
    "            (\"0.710000-0.920000\", \"pending\"),\n",
    "        ],\n",
    "        \"best\": 0.651,\n",
    "    },\n",
    "    \"F3\": {\n",
    "        \"dims\": 3,\n",
    "        \"queries\": [\n",
    "            (\"0.999999-0.999999-0.000000\", -0.161),\n",
    "            (\"0.500000-0.600000-0.200000\", -0.122),\n",
    "            (\"0.490000-0.610000-0.340000\", -0.033),\n",
    "            (\"0.485000-0.615000-0.345000\", -0.031),\n",
    "            (\"0.480000-0.620000-0.350000\", \"pending\"),\n",
    "        ],\n",
    "        \"best\": -0.031,\n",
    "    },\n",
    "    \"F4\": {\n",
    "        \"dims\": 4,\n",
    "        \"queries\": [\n",
    "            (\"0.400827-0.428837-0.398466-0.449225\", -0.006),\n",
    "            (\"0.400000-0.430000-0.400000-0.450000\", -0.037),\n",
    "            (\"0.410000-0.440000-0.410000-0.460000\", -0.338),\n",
    "            (\"0.400000-0.428000-0.398000-0.449000\", -0.003),\n",
    "            (\"0.398000-0.430000-0.400000-0.448000\", \"pending\"),\n",
    "        ],\n",
    "        \"best\": -0.003,\n",
    "    },\n",
    "    \"F5\": {\n",
    "        \"dims\": 4,\n",
    "        \"queries\": [\n",
    "            (\"0.225929-0.841160-0.884257-0.888829\", 1139.17),\n",
    "            (\"0.220000-0.850000-0.890000-0.900000\", 1264.40),\n",
    "            (\"0.210000-0.860000-0.900000-0.920000\", 1484.13),\n",
    "            (\"0.200000-0.870000-0.910000-0.950000\", 1808.33),\n",
    "            (\"0.190000-0.880000-0.930000-0.980000\", \"pending\"),\n",
    "        ],\n",
    "        \"best\": 1808.33,\n",
    "    },\n",
    "    \"F6\": {\n",
    "        \"dims\": 5,\n",
    "        \"queries\": [\n",
    "            (\"0.059926-0.042164-0.264883-0.999568-0.020803\", -1.36),\n",
    "            (\"0.730000-0.150000-0.730000-0.700000-0.050000\", -0.737),\n",
    "            (\"0.720000-0.140000-0.720000-0.710000-0.040000\", -0.678),\n",
    "            (\"0.710000-0.130000-0.710000-0.720000-0.030000\", -0.680),\n",
    "            (\"0.700000-0.100000-0.700000-0.730000-0.010000\", \"pending\"),\n",
    "        ],\n",
    "        \"best\": -0.678,\n",
    "    },\n",
    "    \"F7\": {\n",
    "        \"dims\": 6,\n",
    "        \"queries\": [\n",
    "            (\"0.050000-0.500000-0.250000-0.200000-0.400000-0.750000\", 1.353),\n",
    "            (\"0.055000-0.490000-0.245000-0.220000-0.420000-0.780000\", 1.271),\n",
    "            (\"0.045000-0.510000-0.255000-0.180000-0.380000-0.720000\", 1.390),\n",
    "            (\"0.040000-0.520000-0.265000-0.160000-0.360000-0.700000\", 1.376),\n",
    "            (\"0.045000-0.510000-0.255000-0.180000-0.380000-0.720000\", \"pending\"),\n",
    "        ],\n",
    "        \"best\": 1.390,\n",
    "    },\n",
    "    \"F8\": {\n",
    "        \"dims\": 8,\n",
    "        \"queries\": [\n",
    "            (\"0.069392-0.052126-0.009451-0.005710-0.560896-0.321453-0.013713-0.233966\", 9.780),\n",
    "            (\"0.060000-0.040000-0.010000-0.010000-0.550000-0.350000-0.015000-0.250000\", 9.787),\n",
    "            (\"0.055000-0.035000-0.008000-0.008000-0.540000-0.360000-0.012000-0.260000\", 9.782),\n",
    "            (\"0.050000-0.030000-0.006000-0.006000-0.535000-0.365000-0.010000-0.265000\", 9.777),\n",
    "            (\"0.055000-0.035000-0.008000-0.008000-0.545000-0.355000-0.012000-0.258000\", \"pending\"),\n",
    "        ],\n",
    "        \"best\": 9.787,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Display summary\n",
    "summary_data = []\n",
    "for func, data in results.items():\n",
    "    summary_data.append({\n",
    "        \"Function\": func,\n",
    "        \"Dimensions\": data[\"dims\"],\n",
    "        \"Queries\": len(data[\"queries\"]),\n",
    "        \"Best Output\": data[\"best\"],\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nResults Summary (After Round 5):\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gaussian Process Surrogate Model\n",
    "\n",
    "The GP provides predictions with uncertainty estimates, crucial for balancing exploration and exploitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gp_surrogate(length_scale=0.5, noise_level=0.1, n_restarts=10):\n",
    "    \"\"\"\n",
    "    Create a Gaussian Process surrogate model.\n",
    "    \n",
    "    Args:\n",
    "        length_scale: RBF kernel length scale\n",
    "        noise_level: Observation noise level\n",
    "        n_restarts: Number of optimizer restarts\n",
    "        \n",
    "    Returns:\n",
    "        Configured GaussianProcessRegressor\n",
    "    \"\"\"\n",
    "    kernel = (\n",
    "        ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \n",
    "        RBF(length_scale=length_scale, length_scale_bounds=(1e-3, 1e1)) + \n",
    "        WhiteKernel(noise_level=noise_level, noise_level_bounds=(1e-10, 1e1))\n",
    "    )\n",
    "    \n",
    "    gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        n_restarts_optimizer=n_restarts,\n",
    "        normalize_y=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return gp\n",
    "\n",
    "print(\"GP surrogate model function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Acquisition Functions\n",
    "\n",
    "These functions guide where to query next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_confidence_bound(X, gp, beta=2.0):\n",
    "    \"\"\"\n",
    "    UCB acquisition function: Î¼(x) + Î² * Ïƒ(x)\n",
    "    Higher Î² â†’ more exploration\n",
    "    \"\"\"\n",
    "    mean, std = gp.predict(X, return_std=True)\n",
    "    return mean + beta * std\n",
    "\n",
    "\n",
    "def expected_improvement(X, gp, y_best, xi=0.01):\n",
    "    \"\"\"\n",
    "    Expected Improvement: E[max(f(x) - y_best, 0)]\n",
    "    \"\"\"\n",
    "    mean, std = gp.predict(X, return_std=True)\n",
    "    std = np.maximum(std, 1e-9)\n",
    "    \n",
    "    z = (mean - y_best - xi) / std\n",
    "    ei = (mean - y_best - xi) * norm.cdf(z) + std * norm.pdf(z)\n",
    "    ei[std < 1e-9] = 0.0\n",
    "    \n",
    "    return ei\n",
    "\n",
    "\n",
    "def format_query(x):\n",
    "    \"\"\"Format query for portal submission.\"\"\"\n",
    "    x = np.clip(x, 0.0, 0.999999)\n",
    "    return \"-\".join([f\"{val:.6f}\" for val in x])\n",
    "\n",
    "\n",
    "print(\"Acquisition functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimisation Loop\n",
    "\n",
    "The main Bayesian optimisation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_next_point(X, Y, bounds, acquisition=\"ucb\", beta=2.0, n_random=1000):\n",
    "    \"\"\"\n",
    "    Suggest the next query point using Bayesian optimisation.\n",
    "    \n",
    "    Args:\n",
    "        X: Observed inputs\n",
    "        Y: Observed outputs\n",
    "        bounds: [(min, max), ...] for each dimension\n",
    "        acquisition: 'ucb' or 'ei'\n",
    "        beta: UCB exploration parameter\n",
    "        n_random: Number of random candidates\n",
    "        \n",
    "    Returns:\n",
    "        x_next: Suggested query point\n",
    "        acq_value: Acquisition value\n",
    "    \"\"\"\n",
    "    # Fit GP\n",
    "    gp = create_gp_surrogate()\n",
    "    gp.fit(X, Y)\n",
    "    \n",
    "    y_best = np.max(Y)\n",
    "    n_dims = X.shape[1]\n",
    "    bounds = np.array(bounds)\n",
    "    \n",
    "    # Random search\n",
    "    X_random = np.random.uniform(\n",
    "        bounds[:, 0], bounds[:, 1], \n",
    "        size=(n_random, n_dims)\n",
    "    )\n",
    "    \n",
    "    # Compute acquisition values\n",
    "    if acquisition == \"ucb\":\n",
    "        acq_values = upper_confidence_bound(X_random, gp, beta=beta)\n",
    "    else:\n",
    "        acq_values = expected_improvement(X_random, gp, y_best)\n",
    "    \n",
    "    # Select best\n",
    "    best_idx = np.argmax(acq_values)\n",
    "    x_next = X_random[best_idx]\n",
    "    \n",
    "    return x_next, acq_values[best_idx], gp\n",
    "\n",
    "\n",
    "print(\"Optimisation loop defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Analysis\n",
    "\n",
    "Visualise the optimisation progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot convergence for all functions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Best values per round (cumulative best)\n",
    "convergence_data = {\n",
    "    \"F1\": [0, 0, 0, 2.68e-9, 2.68e-9],\n",
    "    \"F2\": [0.611, 0.611, 0.611, 0.651, 0.651],\n",
    "    \"F3\": [-0.035, -0.035, -0.035, -0.033, -0.031],\n",
    "    \"F4\": [-4.03, -0.006, -0.006, -0.006, -0.003],\n",
    "    \"F5\": [1088.86, 1139.17, 1264.40, 1484.13, 1808.33],\n",
    "    \"F6\": [-0.71, -0.71, -0.71, -0.678, -0.678],\n",
    "    \"F7\": [1.365, 1.365, 1.365, 1.390, 1.390],\n",
    "    \"F8\": [9.60, 9.78, 9.787, 9.787, 9.787],\n",
    "}\n",
    "\n",
    "for i, (func, values) in enumerate(convergence_data.items()):\n",
    "    ax = axes[i]\n",
    "    rounds = [\"Init\", \"R1\", \"R2\", \"R3\", \"R4\"]\n",
    "    \n",
    "    ax.plot(rounds, values, 'b-o', linewidth=2, markersize=8)\n",
    "    ax.fill_between(range(len(values)), values, alpha=0.3)\n",
    "    \n",
    "    # Highlight best\n",
    "    best_idx = np.argmax(values)\n",
    "    ax.scatter([best_idx], [values[best_idx]], color='red', s=150, marker='*', zorder=5)\n",
    "    \n",
    "    ax.set_title(f\"{func} ({FUNCTIONS[i+1]['dims']}D)\", fontsize=12)\n",
    "    ax.set_xlabel(\"Round\")\n",
    "    ax.set_ylabel(\"Best Output\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Optimisation Progress: Best Output per Round\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/figures/convergence.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Convergence plot saved to results/figures/convergence.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "| Function | Trend | Notes |\n",
    "|----------|-------|-------|\n",
    "| **F1** | âŒ Struggling | Extremely weak signal, need more exploration |\n",
    "| **F2** | âœ… Good | Found optimum region around (0.70, 0.93) |\n",
    "| **F3** | âœ… Improving | Steady progress toward local optimum |\n",
    "| **F4** | âœ… Excellent | Recovered from R3 misstep, near-zero output |\n",
    "| **F5** | ðŸš€ Outstanding | +66% improvement, clear unimodal structure |\n",
    "| **F6** | âœ… Plateau | Approaching optimum, diminishing returns |\n",
    "| **F7** | âœ… Stable | Found good region, fine-tuning |\n",
    "| **F8** | âœ… Plateau | Near-optimal, limited improvement possible |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Next Queries\n",
    "\n",
    "Generate and format queries for the next round submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 5 submissions (already submitted)\n",
    "round_5_queries = {\n",
    "    \"F1\": \"0.600000-0.400000\",\n",
    "    \"F2\": \"0.710000-0.920000\",\n",
    "    \"F3\": \"0.480000-0.620000-0.350000\",\n",
    "    \"F4\": \"0.398000-0.430000-0.400000-0.448000\",\n",
    "    \"F5\": \"0.190000-0.880000-0.930000-0.980000\",\n",
    "    \"F6\": \"0.700000-0.100000-0.700000-0.730000-0.010000\",\n",
    "    \"F7\": \"0.045000-0.510000-0.255000-0.180000-0.380000-0.720000\",\n",
    "    \"F8\": \"0.055000-0.035000-0.008000-0.008000-0.545000-0.355000-0.012000-0.258000\",\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ROUND 5 SUBMISSIONS\")\n",
    "print(\"=\"*60)\n",
    "for func, query in round_5_queries.items():\n",
    "    print(f\"\\n{func}: {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After 5 rounds of Bayesian optimisation:\n",
    "\n",
    "1. **F5** shows the most dramatic improvement (+66%), demonstrating successful exploitation of a unimodal structure\n",
    "2. **F1** remains challengingâ€”the signal is extremely weak, suggesting either a very narrow peak or sparse optimum\n",
    "3. **F4** demonstrated the value of reverting to successful regions after failed exploration\n",
    "4. Higher-dimensional functions (F6-F8) show slower but steady convergence\n",
    "\n",
    "### Lessons Learned\n",
    "\n",
    "- **Exploitation over exploration** proved more reliable with limited queries\n",
    "- **Gradient information** from round-by-round changes guided effective adjustments\n",
    "- **Reverting to successful regions** after exploration failures was crucial (F4, F7)\n",
    "\n",
    "---\n",
    "\n",
    "*Imperial College Business School - ML & AI Capstone Project*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
